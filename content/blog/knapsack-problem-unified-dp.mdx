---
title: "0-1 Knapsack Problem: Clean DP Solution with Unified Semantics and Space Optimization"
description: "Master the classic 0-1 Knapsack problem with a clean, unified approach to dynamic programming. Learn elegant 2D DP semantics, optimize to space-efficient 1D DP, and understand backtracking for solution reconstruction. Includes complete JavaScript implementations with clear boundary handling."
date: 2025-09-23T18:00:00.000Z
tags:
  - JavaScript
  - Algorithms
  - Data Structures
  - Interview
published: true
---

The **0-1 Knapsack problem** is one of the most fundamental examples in dynamic programming (DP). It's a classic that appears in technical interviews and serves as an excellent introduction to state-based optimization. However, many tutorials present the solution in a fragmented way that can feel unintuitive.

In this article, I'll show you a **unified, elegant approach** that makes the logic crystal clear, followed by space optimization techniques that you'll use in real-world scenarios.

> **What you'll learn**: Clean DP semantics, systematic boundary handling, and the path from 2D to 1D optimization—skills that transfer to many other DP problems like [unique BST counting](/blog/unique-binary-search-trees-dynamic-programming-catalan).

---

## Problem Definition

You are given a knapsack with capacity `N` and `M` items. Each item `i` has a weight `w[i]` and a value `v[i]`.

You can either take or skip each item (0-1 choice). The goal is to **maximize the total value** without exceeding the capacity.

**Example:**
- Capacity: 5
- Items: `weights = [2,1,3,2]`, `values = [4,2,3,2]`
- Optimal solution: Take items 0 and 2 → total weight: 5, total value: 7

---

## 2D DP: Unified Semantics and Formula

The key to clean DP is defining consistent semantics. Let's use a DP table `dp[i][c]` where:

- `i` represents **using the first i items** (indices 0 through i-1)
- `c` represents a knapsack capacity of `c`

**Therefore: `dp[i][c]` = maximum value achievable with the first `i` items and capacity `c`**

### Boundary Conditions

- **No items**: `dp[0][c] = 0` for any capacity
- **Zero capacity**: `dp[i][0] = 0` for any number of items

These boundaries are automatically satisfied when we initialize our DP table with zeros.

### Transition Formula



For each item `i` (corresponding to array index `i-1` with weight `w` and value `v`):

$$
dp[i][c] = \max(dp[i-1][c],\ dp[i-1][c-w] + v) \quad (c \ge w)
$$

$$
dp[i][c] = dp[i-1][c] \quad (c < w)
$$

The logic is simple: either skip the item (take `dp[i-1][c]`) or include it (take `dp[i-1][c-w] + v`).

### JavaScript Implementation

```javascript
function knapsack2D(capacity, weights, values) {
  const M = weights.length;
  const N = capacity;

  // Initialize DP table with zeros
  const dp = Array.from({ length: M + 1 }, () => new Array(N + 1).fill(0));

  for (let i = 1; i <= M; i++) {
    const w = weights[i - 1];  // Current item weight
    const v = values[i - 1];   // Current item value

    for (let c = 1; c <= N; c++) {
      dp[i][c] = dp[i - 1][c]; // Skip item

      if (c >= w) {
        dp[i][c] = Math.max(dp[i][c], dp[i - 1][c - w] + v); // Take item
      }
    }
  }

  return dp[M][N];
}

// Test cases
console.log(knapsack2D(1, [2,2,3,1,5,2], [2,3,1,5,4,3])); // 5
console.log(knapsack2D(5, [2,1,3,2], [4,2,3,2]));         // 7
```

### Understanding 2D DP Flexibility

One of the beautiful aspects of 2D DP is its **loop order independence**. Unlike the 1D optimization we'll see later, the 2D approach works regardless of how you nest your loops.

#### Loop Order Independence

Both of these implementations work perfectly:

```javascript
// Items first, then capacity (what we used above)
for (let i = 1; i <= M; i++) {
  for (let c = 1; c <= N; c++) {
    // process dp[i][c]
  }
}

// Capacity first, then items
for (let c = 1; c <= N; c++) {
  for (let i = 1; i <= M; i++) {
    // process dp[i][c]
  }
}
```

#### Why Both Orders Work

The key insight is **memory independence**:

- **Reading**: `dp[i][c]` depends on `dp[i-1][c]` and `dp[i-1][c-w]` (previous row only)
- **Writing**: We write to `dp[i][c]` (current row only)
- **No conflicts**: Cells within the same row don't depend on each other

Since `dp[i][c]` only needs data from row `i-1`, the order we process cells within row `i` is irrelevant. Whether we go left-to-right or right-to-left through capacities, or even process capacities in random order, doesn't matter—all the data we need (`dp[i-1][*]`) is already computed.

#### Iteration Direction Freedom

Similarly, within each loop, direction doesn't matter:

```javascript
// Forward capacity iteration (c = 1 to N)
for (let c = 1; c <= N; c++) { /* works */ }

// Backward capacity iteration (c = N to 1)
for (let c = N; c >= 1; c--) { /* also works */ }
```

This flexibility will contrast sharply with the 1D optimization, where iteration direction becomes critical.

#### Alternative 2D Implementation

Here's a working implementation with **swapped loop order** to demonstrate the flexibility:

```javascript
function knapsack2D_alternative(capacity, weights, values) {
  const M = weights.length;
  const N = capacity;
  const dp = Array.from({ length: M + 1 }, () => new Array(N + 1).fill(0));

  // Capacity loop OUTSIDE, items loop INSIDE
  for (let c = 1; c <= N; c++) {
    for (let i = 1; i <= M; i++) {
      const w = weights[i - 1];
      const v = values[i - 1];

      dp[i][c] = dp[i - 1][c]; // Still reading from previous row
      if (c >= w) {
        dp[i][c] = Math.max(dp[i][c], dp[i - 1][c - w] + v);
      }
    }
  }

  return dp[M][N];
}

// Same results as the original implementation
console.log(knapsack2D_alternative(5, [2,1,3,2], [4,2,3,2])); // 7
```

The key insight: `dp[i][c]` depends only on `dp[i-1][*]`, so the order we fill row `i` doesn't matter.

### Why This Approach Is Elegant

1. **Unified semantics**: `dp[i][c]` always means "first `i` items, capacity `c`"
2. **Natural boundaries**: No special initialization needed beyond zeros
3. **Consistent formula**: Every state uses the same transition logic
4. **Intuitive result**: Answer is simply `dp[M][N]`

---

## Space Optimization: 2D to 1D DP

The 2D solution uses `O(M×N)` space, but notice that each row only depends on the **previous row**. We can optimize this to `O(N)` space using a 1D array.

### Transition
$$
dp[c] = \max(dp[c],\ dp[c-w] + v) \quad (c \ge w)
$$

### The Key Insight

Let `dp[c]` represent the maximum value for capacity `c` using items processed so far.

**Critical requirement**: When processing each item, we must iterate capacity **backwards** (from N down to the item's weight) to avoid overwriting values we still need.

### The Critical Backward Iteration Requirement

This is where 1D DP becomes tricky. Unlike 2D DP where we had separate memory for each row, here we're **reusing the same array** to simulate multiple rows. This creates a fundamental dependency problem that requires careful iteration order.

#### Memory Reuse Challenge

To understand why iteration direction matters, let's see the difference in memory access patterns using a concrete example.

**2D DP: Separate Memory for Each Row**
```javascript
// Processing item with weight=2, value=3
// Before processing item i:
dp[i-1] = [0, 1, 2, 4, 5]  // Previous row (READ from these values)
dp[i]   = [0, 0, 0, 0, 0]  // Current row (WRITE to these values)

// Computing dp[i][4]: need dp[i-1][4] and dp[i-1][2]
//                           ↑ safe to read   ↑ safe to read
```

**1D DP: Same Array Reused**
```javascript
// Same processing, but reusing one array:
// Before processing item i:
dp = [0, 1, 2, 4, 5]  // These represent "previous row" values

// When computing dp[4]: need current dp[4] and dp[2]
//                            ↑ old value    ↑ must stay old!
// Problem: if we update dp[2] first, we lose the old value we need for dp[4]!
```

**Key insight**: In 2D, reading from `dp[i-1]` and writing to `dp[i]` are separate. In 1D, we're reading and writing to the same locations!

#### Step-by-Step: Why Forward Iteration Fails

Let's trace through processing an item with weight=2, value=3 on array `dp = [0, 1, 2, 4, 5]`:

**Forward iteration (WRONG):**
```javascript
for (let c = 2; c <= 4; c++) {
  dp[c] = Math.max(dp[c], dp[c-2] + 3);
}

// Step 1: c=2
dp[2] = max(2, dp[0] + 3) = max(2, 3) = 3
// Array now: [0, 1, 3, 4, 5]

// Step 2: c=3
dp[3] = max(4, dp[1] + 3) = max(4, 4) = 4
// Array now: [0, 1, 3, 4, 5]

// Step 3: c=4 (THE PROBLEM!)
dp[4] = max(5, dp[2] + 3) = max(5, 3 + 3) = 6
//                    ^^^
//            This is the NEW value we just computed!
//            We needed the OLD value (2) from before processing this item!
```

**Backward iteration (CORRECT):**
```javascript
for (let c = 4; c >= 2; c--) {
  dp[c] = Math.max(dp[c], dp[c-2] + 3);
}

// Step 1: c=4
dp[4] = max(5, dp[2] + 3) = max(5, 2 + 3) = 5
//                    ^^^
//            This is still the OLD value (2)!
// Array now: [0, 1, 2, 4, 5]

// Step 2: c=3
dp[3] = max(4, dp[1] + 3) = max(4, 4) = 4
// Array now: [0, 1, 2, 4, 5]

// Step 3: c=2
dp[2] = max(2, dp[0] + 3) = max(2, 3) = 3
// Array now: [0, 1, 3, 4, 5]
```

#### Simulating the "Previous Row"

Backward iteration ensures that when we compute `dp[c]`, all values `dp[c-w]` that we need still represent the **previous row** (before processing the current item). This is the key insight:

- **`dp[c]`**: Represents "previous row" value (will be overwritten)
- **`dp[c-w]`**: Still represents "previous row" value (because c-w < c, and we're going backwards)

By the time we might overwrite `dp[c-w]`, we've already used it for all computations that needed it.

#### The Dependency Pattern

```
dp[N] needs dp[N-w] (safe: N-w < N)
dp[N-1] needs dp[N-1-w] (safe: N-1-w < N-1)
...
dp[w] needs dp[0] (safe: 0 < w)
```

Going backwards ensures we never corrupt a value before all the computations that need it are complete.

#### What NOT to Do: Forward Iteration Example

Here's the **incorrect** implementation to illustrate why direction matters:

```javascript
function knapsack1D_WRONG(capacity, weights, values) {
  const M = weights.length;
  const N = capacity;
  const dp = new Array(N + 1).fill(0);

  for (let i = 0; i < M; i++) {
    const w = weights[i];
    const v = values[i];

    // WRONG: Forward iteration corrupts needed values!
    for (let c = w; c <= N; c++) {
      //     ^^^^^^^^^^^^ This direction causes the problem
      dp[c] = Math.max(dp[c], dp[c - w] + v);
      //                      ^^^^^^^^^
      //              This might be a value we JUST computed
      //              in this iteration, not from "previous row"!
    }
  }

  return dp[N];
}

// This will give INCORRECT results:
console.log(knapsack1D_WRONG(5, [2,1,3,2], [4,2,3,2])); // Wrong answer!
```

**Why it fails**: When processing capacity `c`, we might read from `dp[c-w]` which was already updated in the current iteration, effectively "double-counting" items.

### JavaScript Implementation (Correct)

```javascript
function knapsack1D(capacity, weights, values) {
  const M = weights.length;
  const N = capacity;

  // dp[c] = max value achievable with capacity c using items processed so far
  const dp = new Array(N + 1).fill(0);

  for (let i = 0; i < M; i++) {
    const w = weights[i];
    const v = values[i];

    // CRITICAL: Iterate backwards from N down to w
    // This ensures dp[c-w] still contains "previous row" value
    for (let c = N; c >= w; c--) {
      // dp[c] = current "previous row" value (will be overwritten)
      // dp[c-w] = "previous row" value we need (safe because c-w < c)
      dp[c] = Math.max(
        dp[c],        // Don't take item i: keep previous result
        dp[c - w] + v // Take item i: previous result for (c-w) + item value
      );
      // Now dp[c] contains "current row" value for this capacity
    }
    // After this loop: dp array represents results with first i+1 items
  }

  return dp[N]; // Max value using all M items with capacity N
}

// Test cases
console.log(knapsack1D(1, [2,2,3,1,5,2], [2,3,1,5,4,3])); // 5
console.log(knapsack1D(5, [2,1,3,2], [4,2,3,2]));         // 7
```

## 2D vs 1D: Understanding the Fundamental Difference

Now that we've seen both approaches, let's analyze what makes them fundamentally different and when each iteration pattern applies.

### Memory Layout Comparison

**2D DP: Separate Memory Locations**
```
Row i-1: [dp[i-1][0], dp[i-1][1], dp[i-1][2], ..., dp[i-1][N]]
Row i:   [dp[i][0],   dp[i][1],   dp[i][2],   ..., dp[i][N]  ]
         ^read from    ^read from   ^write to       ^write to
```

**1D DP: Same Memory Reused**
```
Before: [dp[0], dp[1], dp[2], ..., dp[N]]  // "Previous row" values
After:  [dp[0], dp[1], dp[2], ..., dp[N]]  // "Current row" values
        ^need   ^will   ^might        ^updating
              overwrite overwrite
```

### Dependency Analysis

**2D DP Dependencies:**
- `dp[i][c]` reads from `dp[i-1][c]` and `dp[i-1][c-w]`
- **Key insight**: Different memory locations = no conflicts
- **Result**: Any iteration order works within row `i`

**1D DP Dependencies:**
- `dp[c]` reads from `dp[c]` (old value) and `dp[c-w]` (must be old value!)
- **Key insight**: Same memory locations = potential conflicts
- **Result**: Must preserve "old values" until all computations using them are done

### Iteration Direction Impact

**2D DP - Direction Flexibility:**
```javascript
// Both work equally well
for (c = 1; c <= N; c++) { /* dp[i][c] = f(dp[i-1][c], dp[i-1][c-w]) */ }
for (c = N; c >= 1; c--) { /* dp[i][c] = f(dp[i-1][c], dp[i-1][c-w]) */ }
```

**1D DP - Direction Matters:**
```javascript
// WRONG: Corrupts needed values
for (c = w; c <= N; c++) { dp[c] = f(dp[c], dp[c-w]); }

// CORRECT: Preserves needed values
for (c = N; c >= w; c--) { dp[c] = f(dp[c], dp[c-w]); }
```

### When to Use Each Approach

**Use 2D DP when:**
- Need to reconstruct the solution (backtracking requires 2D table)
- Debugging complex DP logic (easier to visualize state transitions)
- Memory is not a constraint
- Flexibility in implementation order is valuable

**Use 1D DP when:**
- Memory optimization is critical (`O(N)` vs `O(M×N)`)
- Processing large datasets where space matters
- Solution reconstruction is not needed
- You understand the dependency patterns well

### The Core Principle

The fundamental difference isn't just about space—it's about **dependency management**:

- **2D DP**: Dependencies are across different memory locations → iteration order freedom
- **1D DP**: Dependencies are within the same memory → iteration order constraints

Understanding this principle helps you recognize when similar optimizations apply to other DP problems.

### Complexity Analysis

- **Time**: `O(M×N)` (same as 2D DP)
- **Space**: `O(N)` (significant improvement from `O(M×N)`)

This optimization technique applies to many DP problems and is crucial for handling large datasets—similar to the [space optimization patterns](/blog/from-2sum-to-ksum-recursive-optimization) used in other algorithmic contexts.

---

## Extension: Reconstructing the Solution

For interviews or debugging, you might need to know **which items** were selected. This requires the 2D DP table for backtracking:

```javascript
function knapsackWithSolution(capacity, weights, values) {
  const M = weights.length, N = capacity;
  const dp = Array.from({ length: M + 1 }, () => new Array(N + 1).fill(0));

  // Fill the DP table
  for (let i = 1; i <= M; i++) {
    const w = weights[i - 1], v = values[i - 1];
    for (let c = 1; c <= N; c++) {
      dp[i][c] = dp[i - 1][c];
      if (c >= w) {
        dp[i][c] = Math.max(dp[i][c], dp[i - 1][c - w] + v);
      }
    }
  }

  // Backtrack to find selected items
  const selectedItems = [];
  let c = N;

  for (let i = M; i >= 1; i--) {
    // If value changed, this item was included
    if (dp[i][c] !== dp[i - 1][c]) {
      selectedItems.push(i - 1); // Store original index
      c -= weights[i - 1];       // Reduce remaining capacity
    }
  }

  selectedItems.reverse(); // Return in original order
  return {
    maxValue: dp[M][N],
    items: selectedItems
  };
}

console.log(knapsackWithSolution(5, [2,1,3,2], [4,2,3,2]));
// Output: { maxValue: 7, items: [0, 2] }
```

---

## Key Takeaways

When tackling DP problems:

1. **Start with 2D** for conceptual clarity
2. **Optimize to 1D** only after the logic is solid
3. **Define clear semantics** for each state dimension
4. **Handle boundaries naturally** through initialization
5. **Use consistent formulas** to avoid off-by-one errors

The knapsack problem teaches patterns you'll see everywhere: from [array manipulation techniques](/blog/javascript-array-initialization-pitfalls) to more complex optimization problems.

---

**Remember**: Don't just memorize the code. Understand the semantic meaning of each state, maintain consistent transition logic, and you'll write DP solutions that are both **correct and maintainable**.